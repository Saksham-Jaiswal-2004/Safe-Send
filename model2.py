# -*- coding: utf-8 -*-
"""model__.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ATHyHvyuXeaB94746GeGXQ8xWKtiJUOn
"""

import pandas as pd
import numpy as np
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

import os

# Change this to your folder in Drive
folder_path = '/content/drive/MyDrive'

# List all files and folders in this directory
for item in os.listdir(folder_path):
    print(item)

import os

folder_path = '/content/drive/MyDrive/eth-transactions-2025-08-24.csv'
files = os.listdir(folder_path)

print("Files in folder:", files)

data = pd.read_csv("/content/drive/MyDrive/eth-transactions-2025-08-24.csv/2025-08-24.csv")
#pd.set_option('display.max_rows', None)
data.head()

"""# Data Preprocessing"""

data.drop(axis=1, columns=["hash", "chain_id", "from", "to", "sources", "data_4bytes", "included_at_block_height"], inplace=True)
data.head()

"""## Ensure the dtype of data["value"] is not Object"""

data["value"] = pd.to_numeric(data["value"], errors="coerce").astype("Float64")
print(data["value"].dtype)

"""## Reorder the columns"""

cols = ["gas_price", "gas", "gas_tip_cap", "gas_fee_cap", "value", "nonce", "data_size", "tx_type", "timestamp_ms", "included_block_timestamp_ms", "inclusion_delay_ms"]
data = data[cols]
data.head()

"""### Remove those rows where the `inclusion_delay_ms` is less than 0"""

data.drop(data[data["inclusion_delay_ms"] < 0].index, axis=0, inplace=True)
data.reset_index(drop=True, inplace=True)
data.head(10)

"""### Rename the cols as per the paper"""

data.rename({'gas':"gas_limit"}, inplace=True) # didn't change the name, why??
data.head(), data.columns

"""### columns in csv:
1. timestamp_ms: Time when the Tx initiated
2. Value: Value sent in Wei
3. Nonce: Makes the Tx wait until the previous nonce Tx is confirmed (**values need transformation**)
4. gas: gas limit => max amount of gas someone's willing to pay
5. gas_price: price per unit gas
6. gas_tip_cap:
7. gas_fee_cap:
8. data_size: ?
9. timestamp_ms: Tx first seen at
10. included_block_timestamp_ms: Tx first mined at
11. inclusion_delay_ms: Tx ETA (**y values**)

Here, `inclusion_delay_ms = included_block_timestamp_ms - timestamp_ms`

## timestamp_0
timestamp_0 is the time when the Tx is seen in the mempool. Here we are not provided with the exact  
timestamp_0, so we can calculate it approximately by the formula:  
<div style="padding-left:100px"> timestamp_0 = included_block_timestamp_ms âˆ’ inclusion_delay_ms </div>

## timestamp_1
timestamp_1 is the time when the Tx was confirmed by the mining node

## timestamp_1 - timestamp_0 -> To Predict

### Remove the `timestamp_ms` and `included_block_timestamp_ms` cols, as we don't have that info during inferencing
"""

data.drop(axis=1, columns=["included_block_timestamp_ms"], inplace=True)
data.head()

# Not removing the col that has time when the Tx initiated, i.e., timestamp_ms

"""# Exploratory Data Analysis"""

print(f"number of duplicate rows: {data.duplicated().sum()}")
data = data.drop_duplicates()
print(f"number of duplicate rows: {data.duplicated().sum()}")

# counter = 0
# for i in range(data.shape[0]):
#     if counter <= 10 and data.iloc[i, :].equals(data.iloc[i+1, :]):
#         print(f"row={i}", data.iloc[i, :])
#         print('*'*100)
#         counter += 1
data.head()

data.describe().T

"""### Some rows have gas, gas_price,... = 0 (impossible)"""

print(f"Number of incorrect gas_price = {(data["gas_price"] <= 0).sum()}")
print(f"Number of incorrect gas = {(data["gas"] <= 0).sum()}")
print(f"Number of incorrect gas_tip_cap = {(data["gas_tip_cap"] <= 0).sum()}")
print(f"Number of incorrect gas_fee_cap = {(data["gas_fee_cap"] <= 0).sum()}")

data.drop(axis=0,
          index=data[
              (data["gas_price"] <= 0)
              | (data["gas"] <= 0)
              | (data["gas_tip_cap"] <= 0)
              | (data["gas_fee_cap"] <= 0)
          ].index, inplace=True)
print(f"Number of incorrect gas_price = {(data["gas_price"] <= 0).sum()}")
print(f"Number of incorrect gas = {(data["gas"] <= 0).sum()}")
print(f"Number of incorrect gas_tip_cap = {(data["gas_tip_cap"] <= 0).sum()}")
print(f"Number of incorrect gas_fee_cap = {(data["gas_fee_cap"] <= 0).sum()}")

data.shape

data.describe().T

"""### Need to Scale"""

data.head()

data["inclusion_delay_ms"]

"""### Some features are heavily tailed: `value`, `gas_price`, `gas_tip_cap`, `gas_fee_cap`, `nonce`
-> Use the log scaling, then apply StandardScaler

### `gas`, `data_size`
-> Directly apply StandardScaler

### One-Hot Encode `tx_type`
"""

data.head()

import matplotlib.pyplot as plt

# Plot histograms for the heavily tailed features without seaborn
features = ['value', 'gas_price', 'gas_tip_cap', 'gas_fee_cap', 'nonce', 'timestamp_ms']

plt.figure(figsize=(15, 10))

for i, col in enumerate(features, 1):
    plt.subplot(2, 3, i)
    plt.hist(data[col].dropna(), bins=100)
    plt.title(f"Histogram of {col}")
    plt.xlabel(col)
    plt.ylabel("Frequency")

plt.tight_layout()
plt.show()

data[data["inclusion_delay_ms"] == data["inclusion_delay_ms"].max()]
# These transactions took the longest 27-28 hrs to be confirmed (why??)

from sklearn.preprocessing import StandardScaler

features = ['value', 'gas_price', 'gas_tip_cap', 'gas_fee_cap', 'nonce', 'timestamp_ms']
plt.figure(figsize=(15, 10))
for idx, feature in enumerate(features, 1):
    plt.subplot(2, 3, idx)
    data[feature] = np.log1p(data[feature])
    data[feature] = StandardScaler().fit_transform(data[feature].values.reshape(-1, 1))
    plt.hist(data[feature], bins=100)
    plt.title(f"Histogram of {feature}")

plt.tight_layout()
plt.show()

data["gas"] = StandardScaler().fit_transform(data["gas"].values.reshape(-1, 1))
data["data_size"] = StandardScaler().fit_transform(data["data_size"].values.reshape(-1, 1))

data.head()

data.describe().T

data = pd.get_dummies(data, columns=["tx_type"], dtype=int)

data = data[[col_name for col_name in data.columns if col_name != 'inclusion_delay_ms'] + ['inclusion_delay_ms']]
data.head()

data.describe().T

"""### Remove value col -> Testing"""

data.drop(axis=1, columns=["value"], inplace=True)
data.head()

data["inclusion_delay_ms"].describe().T

print(f"Before removing: {len(data[data["inclusion_delay_ms"] == 0])}")
data = data[data['inclusion_delay_ms'] != 0]
print(f"After removing: {len(data[data["inclusion_delay_ms"] == 0])}")

from sklearn.model_selection import train_test_split
y = data["inclusion_delay_ms"]
data = data.iloc[:, :-1]

import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

feature = "inclusion_delay_ms"
plt.figure(figsize=(15, 10))
plt.subplot(3, 2, 1)
plt.hist(y, bins=100)
plt.title(f"Histogram of {feature} (before)")

y_log = np.log1p(y)
scaler_y = StandardScaler()
y_scaled = pd.Series(
    scaler_y.fit_transform(y_log.values.reshape(-1, 1)).ravel(),
    index=y.index,
    name=feature
)
plt.subplot(3, 2, 2)
plt.hist(y_scaled, bins=100)
plt.title(f"Histogram of {feature} (after)")

plt.show()

"""# Training -- Random Forest"""

type(y_scaled)

X_train, X_test, y_train, y_test = train_test_split(data, y_scaled, test_size=0.2, random_state=42)

X_train = X_train[:100_000]
X_test = X_test[:100_000]
y_train = y_train[:100_000]
y_test = y_test[:100_000]

X_train.head()

y_train

"""250 trees/5 samples"""

import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm # Import tqdm

# --- 1. Model Definition ---
# A simple feed-forward neural network for regression.
class TransactionPredictor(nn.Module):
    def __init__(self, input_features):
        """
        Initializes the neural network layers.
        Args:
            input_features (int): The number of input features for the model.
        """
        super(TransactionPredictor, self).__init__()
        self.layer_stack = nn.Sequential(
            nn.Linear(input_features, 128),
            nn.ReLU(),
            nn.Dropout(0.2), # Dropout layer to prevent overfitting
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1) # Output layer: 1 neuron for the predicted time
        )

    def forward(self, x):
        """
        Defines the forward pass of the network.
        """
        return self.layer_stack(x)

# --- 2. Data Loading ---
def load_data(filepath):
    """
    Loads data from a CSV and separates features and target.
    """
    # Load the dataset
    df = pd.read_csv(filepath)

    # Drop the unnamed column if it exists
    if 'Unnamed: 0' in df.columns:
        df = df.drop('Unnamed: 0', axis=1)

    # Define features (X) and target (y)
    # Assuming the last column is the target variable
    X = df.iloc[:, :-1]
    y = df.iloc[:, -1]

    return X, y

# --- 3. Training Loop ---
def train_model(model, train_loader, criterion, optimizer, epochs=100):
    """
    The main training loop for the model.
    """
    print("Starting training...")
    for epoch in range(epochs):
        model.train() # Set the model to training mode
        running_loss = 0.0
        # Wrap the train_loader with tqdm for a progress bar
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}", leave=False)
        for features, labels in progress_bar:
            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(features)
            loss = criterion(outputs, labels)

            # Backward pass and optimize
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            # Update the progress bar with the current loss
            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})


        # Print loss statistics every 10 epochs
        if (epoch + 1) % 10 == 0:
            print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')
    print("Training finished.")

# --- 4. Evaluation ---
def evaluate_model(model, X_test, y_test, criterion):
    """
    Evaluates the model on the test dataset.
    """
    model.eval() # Set the model to evaluation mode
    with torch.no_grad(): # No need to calculate gradients during evaluation
        predictions = model(X_test)
        loss = criterion(predictions, y_test)
        # We can also use Root Mean Squared Error for more interpretable results
        rmse = torch.sqrt(loss)
        print(f'Test Loss (MSE): {loss.item():.4f}')
        print(f'Test Root Mean Squared Error (RMSE): {rmse.item():.4f} seconds')


# --- Main Execution ---
if __name__ == '__main__':
    # Configuration
    FILE_PATH = 'transactions.csv'
    INPUT_FEATURES = 13 # Number of feature columns in the CSV
    LEARNING_RATE = 0.001
    EPOCHS = 150
    BATCH_SIZE = 32

    # 1. Load data
    X, y = load_data(FILE_PATH)

    # 2. Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Your custom slicing would go here, for example:
    # X_train = X_train[:100_000]
    # X_test = X_test[:100_000]
    # y_train = y_train[:100_000]
    # y_test = y_test[:100_000]

    # 3. Scale the features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # 4. Convert arrays to PyTorch Tensors
    X_train_tensor = torch.FloatTensor(X_train_scaled)
    y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)
    X_test_tensor = torch.FloatTensor(X_test_scaled)
    y_test_tensor = torch.FloatTensor(y_test.values).view(-1, 1)

    # 5. Create DataLoader for batching
    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)

    # 6. Initialize model, loss, and optimizer
    model = TransactionPredictor(input_features=INPUT_FEATURES)
    criterion = nn.MSELoss() # Mean Squared Error is common for regression
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # 7. Train the model
    train_model(model, train_loader, criterion, optimizer, epochs=EPOCHS)

    # 8. Evaluate the model
    print("\n--- Evaluating on Test Data ---")
    evaluate_model(model, X_test_tensor, y_test_tensor, criterion)

    # 9. Example Prediction on a new data point
    print("\n--- Example Prediction ---")
    # This data should look like a single row from your dataset (before scaling)
    # The values are based on the first row of your provided data
    new_data_point = torch.FloatTensor([
        0.179713, -0.186642, 0.806470, 0.179713, -0.330289, -0.136267,
        -1.239722, 1, 0, 0, 0, 0, 0
    ]).view(1, -1) # Create a 2D tensor for a single sample

    # IMPORTANT: Scale the new data point using the *same scaler* from training
    new_data_scaled = torch.FloatTensor(scaler.transform(new_data_point.numpy()))

    model.eval()
    with torch.no_grad():
        prediction = model(new_data_scaled)
        print(f"Input Features:\n{new_data_point.numpy().flatten()}")
        print(f"Predicted Confirmation Time: {prediction.item():.2f} seconds")

import joblib

# Example path in your Drive
path = "/content/drive/MyDrive/random_forest_500.pkl"

# Save the model
joblib.dump(rf, path)
print(f"Model saved to {path}")

X_train.shape

y_train.describe()

# y_test_scaled: true values
# y_pred_scaled: predicted values

tolerance = 0.20  # 20%
pred_acc = np.mean(np.isclose(y_test, y_pred, rtol=tolerance)) * 100

print(f"Pred (0.20): {pred_acc:.2f}%")

def reverseY(y_scaled):
    # ensure numpy array
    y_scaled = np.array(y_scaled).reshape(-1, 1)

    # undo standardization
    y_log = scaler_y.inverse_transform(y_scaled).ravel()

    # undo log1p
    y_original = np.expm1(y_log)
    return y_original

y_pred_scaled = rf.predict(X_test)
print(y_pred_scaled)
y_pred = reverseY(y_pred_scaled)
y_test = reverseY(y_test)

y_pred = y_pred/1e3

y_test = y_test/1e3

print(f"y_pred = {y_pred}")
print(f"y_test = {y_test}")

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# MAE (Mean Absolute Error)
mae = mean_absolute_error(y_test, y_pred)

# RMSE (Root Mean Squared Error)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

# RÂ² (Coefficient of Determination)
r2 = r2_score(y_test, y_pred)

print("MAE:", mae)
print("RMSE:", rmse)
print("RÂ²:", r2)

X_test

X_test.columns

